{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "from pandas.io.parsers import read_csv\n",
    "\n",
    "signnames = read_csv(\"signnames.csv\").values[:, 1]\n",
    "\n",
    "training_file =  'datasets/train.p'\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "X_train, y_train = train['features'], train['labels']\n",
    "\n",
    "validation_file =   'datasets/valid.p'\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)   \n",
    "X_valid, y_valid = valid['features'], valid['labels']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- `'features'` is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).\n",
    "- `'labels'` is a 1D array containing the label/class id of the traffic sign. The file `signnames.csv` contains id -> name mappings for each id.\n",
    "- `'sizes'` is a list containing tuples, (width, height) representing the original width and height the image.\n",
    "- `'coords'` is a list containing tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image. **THESE COORDINATES ASSUME THE ORIGINAL IMAGE. THE PICKLED DATA CONTAINS RESIZED VERSIONS (32 by 32) OF THESE IMAGES**\n",
    "\n",
    "Complete the basic data summary below. Use python, numpy and/or pandas methods to calculate the data summary rather than hard coding the results. For example, the [pandas shape method](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.shape.html) might be useful for calculating some of the summary results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide a Basic Summary of the Data Set Using Python, Numpy and/or Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of validation examples = 4410\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n",
      "Average examples per class = 809\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNnCIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbdc7b33dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pandas.io.parsers import read_csv\n",
    "signnames = read_csv(\"signnames.csv\").values[:, 1]\n",
    "\n",
    "n_train = len(y_train)\n",
    "n_valid = len(y_valid)\n",
    "image_shape = X_train[0,:,:,:].shape\n",
    "n_classes = max(y_train+1)\n",
    "sign_classes, class_indices, class_counts = np.unique(y_train, return_index = True, return_counts = True)\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of validation examples =\", n_valid)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)\n",
    "print(\"Average examples per class =\", int(np.average(class_counts)))\n",
    "\n",
    "image_size = image_shape[0]\n",
    "\n",
    "pyplot.bar( np.arange( 43 ), class_counts, align='center' )\n",
    "pyplot.xlabel('Class')\n",
    "pyplot.ylabel('Count')\n",
    "pyplot.xlim([-1, 43])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include an exploratory visualization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def show_dataset(X,y):\n",
    "    print(\"X shape:\",X.shape,\"/ y.shape\", y.shape)\n",
    "    print()\n",
    "    col_width = max(len(name) for name in signnames)\n",
    "    sign_classes, class_indices, class_counts = np.unique(y, return_index = True, return_counts = True)\n",
    "    \n",
    "    #Images\n",
    "    for c, c_index, c_count in zip(sign_classes, class_indices, class_counts):\n",
    "        print(\"Class %i: %-*s  %s samples\" % (c, col_width, signnames[c], str(c_count)))\n",
    "        fig = pyplot.figure(figsize = (6, 1))\n",
    "        fig.subplots_adjust(left = 0, right = 2, bottom = 0, top = 2, hspace = 0.1, wspace = 0.1)\n",
    "        random_indices = random.sample(range(c_index, c_index + c_count), 10)\n",
    "        for i in range(10):\n",
    "            axis = fig.add_subplot(1, 10, i + 1, xticks=[], yticks=[])\n",
    "            axis.imshow(X[random_indices[i]], cmap='gray')\n",
    "        pyplot.show()\n",
    "\n",
    "    #Graph   \n",
    "    pyplot.bar(np.arange(43), class_counts, align='center')\n",
    "    pyplot.xlabel('Class')\n",
    "    pyplot.ylabel('Count')\n",
    "    pyplot.xlim([-1, 43])\n",
    "    plt.savefig('data2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data expansion (flipping, skewing, rotation)\n",
    "Function definitions as well as examples of each of the four stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_extend(X, y):\n",
    "    \n",
    "    flip_horizontally = np.array([11, 12, 13, 15, 17, 18, 22, 26, 30, 35])\n",
    "    flip_vertically = np.array([1, 5, 7, 12, 15, 17])\n",
    "    flip_both = np.array([32, 40])\n",
    "    cross_flip = np.array([\n",
    "        [19, 20], [20, 19], \n",
    "        [33, 34], [34, 33], \n",
    "        [36, 37], [37, 36], \n",
    "        [38, 39], [39, 38],])\n",
    "    \n",
    "    num_classes = 43\n",
    "    \n",
    "    X_extended = np.empty([0, X.shape[1], X.shape[2], X.shape[3]], dtype = X.dtype)\n",
    "    y_extended = np.empty([0], dtype = y.dtype)\n",
    "    \n",
    "    for c in range(num_classes):\n",
    "        \n",
    "        X_extended = np.append(X_extended, X[y == c], axis = 0)\n",
    "        \n",
    "        if c in flip_horizontally:\n",
    "            X_extended = np.append(X_extended, X[y == c][:, :, ::-1, :], axis = 0)\n",
    "        y_extended = np.append(y_extended, np.full((X_extended.shape[0] - y_extended.shape[0]), c, dtype = int))\n",
    "        \n",
    "        if c in flip_vertically:\n",
    "            X_extended = np.append(X_extended, X_extended[y_extended == c][:, ::-1, :, :], axis = 0)\n",
    "        y_extended = np.append(y_extended, np.full((X_extended.shape[0] - y_extended.shape[0]), c, dtype = int))\n",
    "        \n",
    "        if c in flip_both:\n",
    "            X_extended = np.append(X_extended, X_extended[y_extended == c][:, ::-1, ::-1, :], axis = 0)\n",
    "        y_extended = np.append(y_extended, np.full((X_extended.shape[0] - y_extended.shape[0]), c, dtype = int))\n",
    "        \n",
    "        if c in cross_flip[:, 0]:\n",
    "            flip_class = cross_flip[cross_flip[:, 0] == c][0][1]\n",
    "            X_extended = np.append(X_extended, X[y == flip_class][:, :, ::-1, :], axis = 0)\n",
    "        y_extended = np.append(y_extended, np.full((X_extended.shape[0] - y_extended.shape[0]), c, dtype = int))\n",
    "        \n",
    "    \n",
    "    return (X_extended, y_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def flip_explanation(X,y):\n",
    "    num_classes = 43\n",
    "    flip_horizontally = np.array([11, 12, 13, 15, 17, 18, 22, 26, 30, 35])\n",
    "    flip_vertically = np.array([1, 5, 7, 12, 15, 17])\n",
    "    flip_both = np.array([32, 40])\n",
    "    cross_flip = np.array([\n",
    "        [19, 20], [20, 19], \n",
    "        [33, 34], [34, 33], \n",
    "        [36, 37], [37, 36], \n",
    "        [38, 39], [39, 38],])\n",
    "    \n",
    "    img = np.empty([4, X.shape[1], X.shape[2], X.shape[3]], dtype = X.dtype)\n",
    "    \n",
    "    fig = pyplot.figure(figsize = (1, 1))\n",
    "    axis = fig.add_subplot(1, 4, 1, xticks=[], yticks=[])\n",
    "    \n",
    "    for c in range(num_classes):\n",
    "        img = np.empty([4, X.shape[1], X.shape[2], X.shape[3]], dtype = X.dtype)\n",
    "        \n",
    "        if c in flip_horizontally:\n",
    "            print(\"Class\",c,\": Horizontal Flip\")\n",
    "            img[0], img[2] = random.choice(X[y == c]), random.choice(X[y==c])\n",
    "            img[1], img[3] = img[0, :, ::-1, :], img[2, :, ::-1, :]\n",
    "\n",
    "        if c in flip_vertically:\n",
    "            print(\"Class\",c,\": Vertical Flip\")\n",
    "            img[0], img[2] = random.choice(X[y == c]), random.choice(X[y==c])\n",
    "            img[1], img[3] = img[0,::-1, :, :], img[2,::-1, :, :]\n",
    "\n",
    "        if c in flip_both:\n",
    "            print(\"Class\",c,\": Diagonal Flip\")\n",
    "            img[0], img[2] = random.choice(X[y == c]), random.choice(X[y==c])\n",
    "            img[1], img[3] = img[0,::-1, ::-1, :], img[2,::-1, ::-1, :]\n",
    "\n",
    "        if c in cross_flip[:, 0]:\n",
    "            print(\"Class\",c,\": Class Changing Flip\")\n",
    "            img[0], img[2] = random.choice(X[y == c]), random.choice(X[y==c])\n",
    "            img[1], img[3] = img[0,:, ::-1, :], img[2,:, ::-1, :]\n",
    "            \n",
    "        if img[0].all() > 0:\n",
    "            fig = pyplot.figure(figsize = (3, 1));\n",
    "            fig.subplots_adjust(left = 0, right = 2, bottom = 0, top = 2, hspace = 0.1, wspace = 0.1);\n",
    "            for i in range(0,4):\n",
    "                axis = fig.add_subplot(1, 4, i + 1, xticks=[], yticks=[])\n",
    "                axis.imshow(img[i])\n",
    "            pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_explanation(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotatating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rotate\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "def rotate_extend(X , y):\n",
    "    \n",
    "    num_classes = 43\n",
    "    average_set_size = int(len(y_train)/num_classes)\n",
    "    _, class_counts = np.unique(y, return_counts = True)\n",
    "    \n",
    "    X_extended = np.empty([0, X.shape[1], X.shape[2], X.shape[3]], dtype = X.dtype)\n",
    "    y_extended = np.empty([0], dtype = y.dtype)\n",
    "    class_images = X_extended\n",
    "    \n",
    "    left = iaa.Sequential([\n",
    "        iaa.Affine(\n",
    "            rotate=(-10, -2),\n",
    "            mode=\"edge\"\n",
    "        )\n",
    "    ])  \n",
    "    right = iaa.Sequential([\n",
    "        iaa.Affine(\n",
    "            rotate=(2, 10),\n",
    "            mode=\"edge\"\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    for c in range(num_classes):\n",
    "        class_images = X[y==c]\n",
    "        \n",
    "        X_extended = np.append(X_extended, class_images, axis = 0)\n",
    "        \n",
    "        if class_counts[c] <= average_set_size:\n",
    "            counterclockwise_images = left.augment_images(class_images)\n",
    "            clockwise_images = right.augment_images(class_images)\n",
    "            X_extended = np.append(X_extended,np.append(counterclockwise_images, clockwise_images, axis = 0) , axis = 0)\n",
    "            \n",
    "        y_extended = np.append(y_extended, np.full((X_extended.shape[0] - y_extended.shape[0]), c, dtype = int))\n",
    "          \n",
    "    return (X_extended, y_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rotate\n",
    "def rotation_explaination(X):\n",
    "    img = [X for i  in range(3)]\n",
    "    img[1] = rotate(img[1], -15, mode='edge')\n",
    "    img[2] = rotate(img[2], 15, mode='edge')\n",
    "\n",
    "    print(\"    Unrotated         Rotated Right      Rotated Left\")\n",
    "    fig = pyplot.figure(figsize = (3, 1))\n",
    "    fig.subplots_adjust(left = 0, right = 2, bottom = 0, top = 2, hspace = 0.1, wspace = 0.1)\n",
    "    for i in range(0,3):\n",
    "        axis = fig.add_subplot(1, 3, i + 1, xticks=[], yticks=[])\n",
    "        axis.imshow(img[i])\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_explaination(X_train[3333])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_extend(X, y):\n",
    "    num_classes = 43\n",
    "    average_set_size = int(len(y_train)/num_classes)\n",
    "    _, class_counts = np.unique(y, return_counts = True)\n",
    "    \n",
    "    X_extended = np.empty([0, X.shape[1], X.shape[2], X.shape[3]], dtype = X.dtype)\n",
    "    y_extended = np.empty([0], dtype = y.dtype)\n",
    "    class_images = X_extended\n",
    "    \n",
    "    downscale = iaa.Sequential([\n",
    "        iaa.Affine(\n",
    "            scale={\"x\": (0.8, 1.0), \"y\": (0.8, 1.0)},\n",
    "            mode=\"reflect\"\n",
    "        )\n",
    "    ])\n",
    "    upscale = iaa.Sequential([\n",
    "        iaa.Affine(\n",
    "            scale={\"x\": (1.0, 1.2), \"y\": (1.0, 1.2)},\n",
    "            mode=\"reflect\"\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    for c in range(num_classes):\n",
    "        class_images = X[y==c]\n",
    "        \n",
    "        X_extended = np.append(X_extended, class_images, axis = 0)\n",
    "        \n",
    "        if class_counts[c] <= average_set_size:\n",
    "            downscale_images = downscale.augment_images(class_images)\n",
    "            upscale_images = upscale.augment_images(class_images)\n",
    "            X_extended = np.append(X_extended,np.append(downscale_images, upscale_images, axis = 0) , axis = 0)\n",
    "            \n",
    "        y_extended = np.append(y_extended, np.full((X_extended.shape[0] - y_extended.shape[0]), c, dtype = int))\n",
    " \n",
    "    return (X_extended, y_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_explaination(X):\n",
    "    img = [X for i  in range(3)]\n",
    "    bothscale = iaa.Sequential([\n",
    "        iaa.Affine(\n",
    "            scale={\"x\": (0.7, 1.3), \"y\": (0.7, 1.3)},\n",
    "            mode=\"edge\"\n",
    "        )\n",
    "    ])   \n",
    "    img[1] = bothscale.augment_image(img[0])\n",
    "    img[2] = bothscale.augment_image(img[0])\n",
    "\n",
    "    print(\"    Untouched         Example One        Example Two \")\n",
    "    fig = pyplot.figure(figsize = (3, 1))\n",
    "    fig.subplots_adjust(left = 0, right = 2, bottom = 0, top = 2, hspace = 0.1, wspace = 0.1)\n",
    "    for i in range(0,3):\n",
    "        axis = fig.add_subplot(1, 3, i + 1, xticks=[], yticks=[])\n",
    "        axis.imshow(img[i])\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scale_explaination(X_train[3333])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_extend(X, y):  \n",
    "    num_classes = 43\n",
    "    average_set_size = int(len(y_train)/num_classes)\n",
    "    _, class_counts = np.unique(y, return_counts = True)\n",
    "    \n",
    "    X_extended = np.empty([0, X.shape[1], X.shape[2], X.shape[3]], dtype = X.dtype)\n",
    "    y_extended = np.empty([0], dtype = y.dtype)\n",
    "    class_images = X_extended\n",
    "    \n",
    "    fine = iaa.Sequential([\n",
    "        iaa.Affine(\n",
    "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "            shear=(-8, 8),\n",
    "            mode=\"edge\"\n",
    "        ),\n",
    "        iaa.Add((-40,40)),\n",
    "        iaa.Sometimes(0.5, iaa.GaussianBlur(sigma=(0.0, 0.5)))\n",
    "    ])\n",
    "    \n",
    "    for c in range(num_classes):\n",
    "        class_images = X[y==c]\n",
    "        \n",
    "        X_extended = np.append(X_extended, class_images, axis = 0)\n",
    "        \n",
    "        if class_counts[c] <= average_set_size:\n",
    "            X_extended = np.append(X_extended, fine.augment_images(class_images), axis = 0)\n",
    "            \n",
    "        y_extended = np.append(y_extended, np.full((X_extended.shape[0] - y_extended.shape[0]), c, dtype = int))\n",
    " \n",
    "    return (X_extended, y_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_explaination(X):\n",
    "    \n",
    "    img = [X for i  in range(3)]\n",
    "    fine = iaa.Sequential([\n",
    "        iaa.Affine(\n",
    "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "            shear=(-8, 8),\n",
    "            mode=\"edge\"\n",
    "        ),\n",
    "        iaa.Add((-40,40)),\n",
    "        iaa.Sometimes(0.5, iaa.GaussianBlur(sigma=(0.0, 0.5)))\n",
    "    ])\n",
    "    img[1] = fine.augment_image(img[0])\n",
    "    img[2] = fine.augment_image(img[0])\n",
    "    \n",
    "    print(\"    Untouched         Example One        Example Two \")\n",
    "    fig = pyplot.figure(figsize = (3, 1))\n",
    "    fig.subplots_adjust(left = 0, right = 2, bottom = 0, top = 2, hspace = 0.1, wspace = 0.1)\n",
    "    for i in range(0,3):\n",
    "        axis = fig.add_subplot(1, 3, i + 1, xticks=[], yticks=[])\n",
    "        axis.imshow(img[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_explaination(X_train[3333])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data Set (normalization, grayscale, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we apply the four data expantions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = flip_extend(X_train, y_train)\n",
    "X_train, y_train = rotate_extend(X_train, y_train) # these attempt\n",
    "X_train, y_train = scale_extend(X_train, y_train)  # to even out the class data\n",
    "X_train, y_train = affine_extend(X_train, y_train) # by only adding to the lowest half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34799, 32, 32, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from skimage import exposure\n",
    "\n",
    "def preprocess_dataset(X, y = None):\n",
    "    #This equation is converting the colors into greyscale\n",
    "    X = 0.299 * X[:, :, :, 0] + 0.587 * X[:, :, :, 1] + 0.114 * X[:, :, :, 2]\n",
    "    \n",
    "    #normalized and mean zero\n",
    "    X = (X - 128)/ 128\n",
    "    \n",
    "    X = X.reshape(X.shape + (1,)) \n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_explaination(X):\n",
    "    fig = pyplot.figure(figsize = (3, 1))\n",
    "    gray_image = np.array((0.299*X[:, :, 0] + 0.587*X[:, :, 1] + 0.114*X[:, :, 2]))\n",
    "    \n",
    "    normalized_image = ((gray_image-128) / 128)\n",
    "    \n",
    "    listed_images = [gray_image, normalized_image]\n",
    "    \n",
    "    print(\"       Greyscale                  Normalized\")\n",
    "    \n",
    "    axis = fig.add_subplot(1, 3, 1, xticks=[], yticks=[])\n",
    "    axis.imshow(X)\n",
    "    axis = fig.add_subplot(1, 3, 2, xticks=[], yticks=[])\n",
    "    axis.imshow(gray_image, cmap='gray')\n",
    "    axis = fig.add_subplot(1, 3, 3, xticks=[], yticks=[])\n",
    "    axis.imshow(normalized_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Greyscale                  Normalized\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALwAAABGCAYAAAB2QP7UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKBSUBF9CoaAk+BIKBSXBl1Ao+F8ueSFWkaLLmwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbdc7b333c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess_explaination(X_train[3333])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocess_dataset(X_train, y_train)\n",
    "X_valid, y_valid = preprocess_dataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "The LeNet-5 implementation shown in the [classroom](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/601ae704-1035-4287-8b11-e2c2716217ad/concepts/d4aca031-508f-4e0b-b493-e7b706120f81) at the end of the CNN lesson is a solid starting point. You'll have to change the number of classes and possibly the preprocessing, but aside from that it's plug and play! \n",
    "\n",
    "With the LeNet-5 solution from the lecture, you should expect a validation set accuracy of about 0.89. To meet specifications, the validation set accuracy will need to be at least 0.93. It is possible to get an even higher accuracy, but 0.93 is the minimum for a successful project submission. \n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Neural network architecture (is the network over or underfitting?)\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf). It's not required to be familiar with the approach used in the paper but, it's good practice to try to read papers like these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "EPOCHS = 75\n",
    "BATCH_SIZE = 128\n",
    "PATIENCE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):    \n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # Layer 1\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Layer 2\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Flatten\n",
    "    fc0   = flatten(conv2)\n",
    "    \n",
    "    # Layer 3\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "\n",
    "    # Layer 4\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(84))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "\n",
    "    # Layer 5\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 43), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate and Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A validation set can be used to assess how well the model is performing. A low accuracy on the training and validation\n",
    "sets imply underfitting. A high accuracy on the training set but low accuracy on the validation set implies overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    best_so_far = 0\n",
    "    patience_cnt = 0\n",
    "\n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for epoch in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        validation_accuracy = evaluate(X_valid, y_valid)\n",
    "        if validation_accuracy>(best_so_far*1.01):\n",
    "            best_so_far = validation_accuracy\n",
    "            patience_cnt = 0\n",
    "            saver.save(sess, './lenet')\n",
    "            print(\"Model saved\")\n",
    "        else:\n",
    "            patience_cnt+=1\n",
    "        if patience_cnt > PATIENCE:\n",
    "            print(\"Early stopping...\")\n",
    "            break\n",
    "        print(\"EPOCH {} ...\".format(epoch+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d2ba684acd0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-593c4ef6290c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtesting_file\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'datasets/test.p'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "testing_file= 'datasets/test.p'\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)   \n",
    "X_test, y_test = test['features'], test['labels']\n",
    "X_test, y_test = preprocess_dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "To give yourself more insight into how your model is working, download at least five pictures of German traffic signs from the web and use your model to predict the traffic sign type.\n",
    "\n",
    "You may find `signnames.csv` useful as it contains mappings from the class id (integer) to the actual sign name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Output the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "filelist = glob.glob('internet test/*.jpg')\n",
    "\n",
    "X_internet = np.array([mpimg.imread(fname) for fname in filelist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Speed limit (20km/h)\n",
      "1: Speed limit (30km/h)\n",
      "2: Speed limit (50km/h)\n",
      "3: Speed limit (60km/h)\n",
      "4: Speed limit (70km/h)\n",
      "5: Speed limit (80km/h)\n",
      "6: End of speed limit (80km/h)\n",
      "7: Speed limit (100km/h)\n",
      "8: Speed limit (120km/h)\n",
      "9: No passing\n",
      "10: No passing for vehicles over 3.5 metric tons\n",
      "11: Right-of-way at the next intersection\n",
      "12: Priority road\n",
      "13: Yield\n",
      "14: Stop\n",
      "15: No vehicles\n",
      "16: Vehicles over 3.5 metric tons prohibited\n",
      "17: No entry\n",
      "18: General caution\n",
      "19: Dangerous curve to the left\n",
      "20: Dangerous curve to the right\n",
      "21: Double curve\n",
      "22: Bumpy road\n",
      "23: Slippery road\n",
      "24: Road narrows on the right\n",
      "25: Road work\n",
      "26: Traffic signals\n",
      "27: Pedestrians\n",
      "28: Children crossing\n",
      "29: Bicycles crossing\n",
      "30: Beware of ice/snow\n",
      "31: Wild animals crossing\n",
      "32: End of all speed and passing limits\n",
      "33: Turn right ahead\n",
      "34: Turn left ahead\n",
      "35: Ahead only\n",
      "36: Go straight or right\n",
      "37: Go straight or left\n",
      "38: Keep right\n",
      "39: Keep left\n",
      "40: Roundabout mandatory\n",
      "41: End of no passing\n",
      "42: End of no passing by vehicles over 3.5 metric tons\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(signnames)):\n",
    "    print(str(i)+\": \"+signnames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-9cdef73f70b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_internet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_internet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_internet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_internet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_internet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_internet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_internet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-385afde16113>\u001b[0m in \u001b[0;36mpreprocess_dataset\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#This equation is converting the colors into greyscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.299\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.587\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.114\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#normalized and mean zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "y_internet = np.array([1,9,14,2,35,11])\n",
    "X_internet, y_internet = preprocess_dataset(X_internet, y_internet)\n",
    "X_internet=X_internet.reshape((6,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,) (6,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c80d68644e59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my_internet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAG4AAAJVCAYAAAA/ecC8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAABaJJREFUeJzt1MFNA1EQBcH9iBDWZzb/WOwgfIYc\nhhBYW7KgRdX5HUZqadbMbPS8/fYBPEe4KOGihIsSLkq4KOGihIsSLur9kfG+73Mcx4tO4Xa7fc3M\n5cz2oXDHcWzX6/W5q/jRWut+dutVRgkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHC\nRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkX\nJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyU\ncFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHC\nRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkX\nJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyU\ncFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHC\nRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkX\nJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyU\ncFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHC\nRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkX\nJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyU\ncFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHC\nRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkX\nJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyU\ncFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHC\nRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkX\nJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyU\ncFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHC\nRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkX\nJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyU\ncFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHC\nRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkXJVyUcFHCRQkX\ntWbm/Hitz23b7q8759/7mJnLmeFD4fg7vMoo4aKEixIuSrgo4aKEixIuSriob+NVHkvSCfeEAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbdc7a5b5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_internet.shape, y_internet.shape)\n",
    "fig = pyplot.figure(figsize = (4, 4))\n",
    "fig.subplots_adjust(left = 0, right = 2, bottom = 0, top = 2, hspace = 0.1, wspace = 0.1)\n",
    "for i in range(0,6):\n",
    "    axis = fig.add_subplot(1, 6, i + 1, xticks=[], yticks=[])\n",
    "    I = random.choice(X_train[y_train==y_internet[i]]).reshape((32, 32))\n",
    "    pyplot.imshow(I,cmap = 'gray')\n",
    "\n",
    "    axis = fig.add_subplot(2, 6, i + 1, xticks=[], yticks=[])\n",
    "    axis.imshow(X_internet[i], cmap='gray')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_internet=X_internet.reshape((6,32,32,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image and Show Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.argmax( logits, 1 )\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias\n",
    "    saver.restore(sess, './lenet')\n",
    "    output = sess.run(prediction, feed_dict={\n",
    "        x: X_internet})\n",
    "    test_accuracy = sess.run(accuracy_operation, feed_dict={x: X_internet, y: y_internet})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predictions:')\n",
    "print(output)\n",
    "print('Real:')\n",
    "print(y_internet)\n",
    "print('Accuracy:')\n",
    "print(test_accuracy)\n",
    "print()\n",
    "print(signnames[output])\n",
    "print()\n",
    "print(signnames[y_internet])\n",
    "fig = pyplot.figure(figsize = (4, 3))\n",
    "fig.subplots_adjust(left = 0, right = 2, bottom = 0, top = 2, hspace = 0.1, wspace = 0.1)\n",
    "\n",
    "for i in range(0,6):\n",
    "   \n",
    "    axis = fig.add_subplot(1, 6, i + 1, xticks=[], yticks=[])\n",
    "    I = X_internet[i].reshape((32, 32))\n",
    "    pyplot.imshow(I,cmap = 'gray')\n",
    "\n",
    "    \n",
    "    axis = fig.add_subplot(2, 6, i + 1, xticks=[], yticks=[])\n",
    "    I = random.choice(X_train[y_train==output[i]]).reshape((32, 32))\n",
    "    pyplot.imshow(I,cmap = 'gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Top 5 Softmax Probabilities For Each Image Found on the Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'saver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-63f8625f7083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./lenet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0msigns_top_5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_internet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'saver' is not defined"
     ]
    }
   ],
   "source": [
    "def test_net(X_data, sess): \n",
    "    prob = sess.run(tf.nn.softmax(logits), feed_dict={x: X_internet})    \n",
    "    top_5 = tf.nn.top_k(prob, k=5)\n",
    "    return sess.run(top_5)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './lenet')\n",
    "    signs_top_5=test_net(X_internet, sess)\n",
    "\n",
    "\n",
    "print(\"Top softmax probabilities:\")\n",
    "plt.figure(figsize=(15, 16))\n",
    "for i in range(6):\n",
    "    plt.subplot(6, 2, 2*i+1)\n",
    "    plt.imshow(X_internet[i].reshape((32,32)), cmap = 'gray') \n",
    "    plt.title(str(i+1)+\": \"+signnames[y_internet[i]])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(6, 2, 2*i+2)\n",
    "    plt.barh(np.arange(1, 6, 1), signs_top_5.values[i, :])\n",
    "    labs=[signnames[j] for j in signs_top_5.indices[i]]\n",
    "    plt.yticks(np.arange(1, 6, 1), labs)\n",
    "plt.savefig('softmax.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    \n",
    "    plt.bar(signs_top_5.indices[i],signs_top_5.values[i], align='center', alpha=0.5)\n",
    "    plt.xlim([0,42])\n",
    "    plt.title(\"confidence for predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network has not seen examples that are closely related to the small 50/km sign or the oddly made stop sign. \n",
    "There is a failure in the methodology that led to these very confident wrong answers, probably from not having these specially written stop signs and from not having small sign examples of 50/km signs, as well as not having a deep enough repersentation of what it means to be in each class. There are some bad examples of blurry indistinguishable signs in the data set that may have led to confusion in edge cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Writeup\n",
    "\n",
    "Once you have completed the code implementation, document your results in a project writeup using this [template](https://github.com/udacity/CarND-Traffic-Sign-Classifier-Project/blob/master/writeup_template.md) as a guide. The writeup can be in a markdown or pdf file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
